Lab 5 - Logfile to API
======================

## Overview

This lab will introduce to parsing an Apache HTTP server log to extract measurements that are then sent to
the measurement APIs


## Apache Web Server Introduction

The [Apache HTTP Server](https://en.wikipedia.org/wiki/Apache_HTTP_Server) has a long history with
its initial release in 1995. The Apache HTTP Server is descendant of the
[NCSA HTTPd Server](https://en.wikipedia.org/wiki/NCSA_HTTPd) and was started when development on the
NCSA HTTPd Server stalled.

A key feature of the Apache Web Server is the ability to log received requests to a log file of
your choosing and format. The out of the box file is named `access_log` and on RHEL/Centos platforms
the path to the file is `/var/log/httpd/access_log`. The default format of the log file is referred to
as `combined`. Information about received requests are continuously appended to the log file.

To extract useful content from the log file at we need to perform the following:

1. Continuously read the log file looking for new requests appended to the log.
2. For each line parse the content knowing the format of each line or record.
3. Extract the content of interest by filtering and searching each line or record.
4. Send the extract content to TrueSight Intelligence using the Measurement API.

## Introduction to _Exercise 5-1 Monitoring a Logfile_

A useful unix utility [`tail`](https://en.wikipedia.org/wiki/Tail_(Unix)) permits the monitoring of a log
file and outputs new lines or records as they are written to the file. An example of using this utility is shown
here:

```
$ tail -f /var/log/cron
```
which is a log that shows [`cron`](https://en.wikipedia.org/wiki/Cron) jobs that have been executed by the system.

For this exercise we will introduce the same capability by in Python code as shown here:

```
def follow(f):
    """
    Reads a line from a file when available
    :param f: open file
    :return: a line from the file
    """
    # Go to the end of the file
    f.seek(0, 2)

    # Loop waiting for lines to be written
    while True:
        log_line = f.readline()
        # If there is nothing to read then wait a bit
        # and try again
        if not log_line:
            time.sleep(0.1)
            continue
        # We have a line return the line
        yield log_line
```

This function uses one of the esoteric features of python namely `yield`. Suffice to the say the above function
returns a line which is append in the file everytime `yield log_line` is executed. This function _generates_ log lines
from the passed in open file and can be iterated over as shown in this Python snippet:

```
# Open our file for reading
log_file = open(sys.argv[1], "r")

# Create our iterable function
log_lines = monitor_file(log_file)

# Process the lines as they are appended to the file
for line in log_lines:
    # Strip out the new line an print the line
    print("{0}".format(line.strip()))
```

if you want to have a deep understanding of how this works take a look at this
[page](https://wiki.python.org/moin/Generators)

Okay, onward to run some examples of what we just learned.


## Exercise 5-1 - Monitoring A Log File

Is this exercise we will run a complete script that opens a file named on the command line
and writes out the lines append to the file.

1. Change directory to `labs/lab-5`

     ```
     [vagrant@tsi-lab-01 ~]$ cd labs/lab-5/
     ```

2. Run the script against the `/var/log/messages` file which is generated by the syslog daemon. You
can monitor what is being written to this file by by running the following command (_NOTE_: the prefixed
`sudo` command is required since `/var/log/messages` is read-only by the `root` user):

    ```
    vagrant@tsi-lab-01 lab-5]$ sudo ./ex5-1.log.py /var/log/messages
    ```

which will present output similar to the following:

```
Apr 14 20:50:11 localhost one-liners.py[26992]: Two cannibals were eating a clown - one ...
Apr 14 20:50:16 localhost one-liners.py[26992]: How do you tell when you're out of invi ...
Apr 14 20:50:21 localhost one-liners.py[26992]: I have a lot of growing up to do. I rea ...
Apr 14 20:50:26 localhost one-liners.py[26992]: Did you hear about the shrimp that went ...
Apr 14 20:50:31 localhost one-liners.py[26992]: The quickest way to a man's heart is th ...
```

If you feeling curious (like the monkey named [George](https://en.wikipedia.org/wiki/Curious_George))
take a gander at the complete script `~/labs/lab-5/ex-5-1.log.py`.

## Introduction to _Exercise 5-2 Parsing an Apache `access_log`_

One of the beauties of Python is there is a heck of a lot of code out there already written for us
that we can leverage in our own scripts. For this lab we want to show how to parse an Apache HTTP server
log file, but who wants to write the parser, we didn't. A quick search of the internet (The thing invented
by former senator and vice president [Al Gore](https://en.wikipedia.org/wiki/Information_superhighway)) yielded
a suitable Python package ripe for the picking: `apachelog`. Using
[`pip`](https://en.wikipedia.org/wiki/Pip_(package_manager)) we can install this package by the following:

```
$ pip install apachelog
```

_NOTE_: No needed to run this we have already installed this in the virtual machine, but thought
you might want to know for that pet log parsing project down the road.

With our new best friend/package parsing an Apache HTTP server log is now trivial. Here you go, a
quick Python snippet that shows you how easy it is:

```
import apachelog

log_format = r'%h %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}\i"'
p = apachelog.parser(log_format)
parsed = p.parse(line)
```

In the above snippet the `parsed` variable contains a Python dictionary with the parsed out log entry with
the format spelled out in `log_format`. Cool Huh? Here is an example value of what the `parsed` values contents:

```
{'%l': '-', '%>s': '200', '%h': '::1', '%b': '481', '%{Referer}i': 'www.bmc.com', '%{User-Agent}\\i"': 'curl/7.29.0', '%u': '-', '%t': '[13/Apr/2016:05:25:25 +0000]', '%r': 'GET / HTTP/1.1'}
```

Let's proceed to the exercise.


## Exercise 5-2 - Parsing an Apache `access_log`

1. Change directory to `labs/lab-5`

     ```
     [vagrant@tsi-lab-01 ~]$ cd labs/lab-5/
     ```

2. Run the following command with sample `access_log` provide:

    ```
    vagrant@tsi-lab-01 lab-5]$ ./ex5-2.log.py access_log
    ```

which displays the following output:

    host: ::1, time: [13/Apr/2016:02:35:06 +0000], request: GET / HTTP/1.1, status: 200 ...
    host: ::1, time: [13/Apr/2016:02:35:14 +0000], request: GET /favicon HTTP/1.1, stat ...
    host: ::1, time: [13/Apr/2016:02:35:21 +0000], request: GET /fav.icon HTTP/1.1, sta ...
    host: ::1, time: [13/Apr/2016:02:36:16 +0000], request: GET /favicon.ico HTTP/1.1,  ...
    host: ::1, time: [13/Apr/2016:03:21:02 +0000], request: GET /fav HTTP/1.1, status:  ...
    host: ::1, time: [13/Apr/2016:03:26:30 +0000], request: GET /favicon.ico HTTP/1.1,  ...
    host: ::1, time: [13/Apr/2016:05:24:35 +0000], request: GET / HTTP/1.0, status: 200 ...
    host: ::1, time: [13/Apr/2016:05:25:25 +0000], request: GET / HTTP/1.1, status: 200 ...

Look at the script `~/labs/lab-5/ex5-2.log.py` in its entirety to understand how it works.

## Introduction to _Exercise 5-3 - Reading live Apache Log Files and Sending Measurements_

Okay, last stop in the log file saga.

## Exercise 5-3 - Reading live Apache Log Files and Sending Measurements

1. Run the following command:
    ```
    $ sudo ex5-3.log.py /var/log/httpd/access_log
    ```

